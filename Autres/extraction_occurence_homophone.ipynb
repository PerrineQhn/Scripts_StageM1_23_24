{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os\n",
    "from conll3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_misc_to_dict(misc):\n",
    "    # Dictionnaire pour stocker les informations supplémentaires\n",
    "    result_dict = {}\n",
    "    pairs = misc.split(\"|\")\n",
    "    for pair in pairs:\n",
    "        key, value = pair.split(\"=\")\n",
    "        result_dict[key] = value\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_occ_homophone_mono(conllu_path:str):\n",
    "    \"\"\"\n",
    "    Extrait les occurrences d'une suite de 2 tokens homophones dans un corpus CoNLL-U.Regarde dans misc syl1.\n",
    "\n",
    "    Parameters:\n",
    "    conllu_path (str): le chemin du fichier CoNLL-U\n",
    "\n",
    "    Returns:\n",
    "    dict: un dictionnaire avec les occurrences des suites de 2 tokens homophones\n",
    "    \"\"\"\n",
    "    occurences = {}\n",
    "    # Convertir le fichier conllu en arbres de dépendances\n",
    "    trees = conllFile2trees(conllu_path)\n",
    "    for tree in trees:\n",
    "        # Convertir l'arbre en chaîne de caractères\n",
    "        tree_str = str(tree)\n",
    "\n",
    "        words = tree.words\n",
    "        index = 1\n",
    "\n",
    "        while index < len(words):\n",
    "            form_T1 = tree[index].get(\"t\", \"_\")\n",
    "            pos = tree[index].get(\"tag\", \"_\")\n",
    "            pos_T1 = pos\n",
    "            misc_T1 = tree[index].get(\"misc\", \"\")\n",
    "            misc_T1_dict = convert_misc_to_dict(misc_T1)\n",
    "            prononciation1 = misc_T1_dict.get(\"Syl1\", \"_\")\n",
    "            syl1_slopeglo = misc_T1_dict.get(\"Syl1SlopeGlo\", \"_\")\n",
    "\n",
    "            idx = index + 1\n",
    "\n",
    "            if idx < len(words):\n",
    "                form_T2 = tree[idx].get(\"t\", \"_\")\n",
    "                pos_T2 = tree[idx].get(\"tag\", \"_\")\n",
    "                misc_T2 = tree[idx].get(\"misc\", \"\")\n",
    "                misc_T2_dict = convert_misc_to_dict(misc_T2)\n",
    "                prononciation2 = misc_T2_dict.get(\"Syl1\", \"_\")\n",
    "                syl1_slopeglo2 = misc_T2_dict.get(\"Syl1SlopeGlo\", \"_\")\n",
    "\n",
    "                if (prononciation1 == prononciation2 and pos_T1 != pos_T2) and (\"Syl2\" not in misc_T1 and \"Syl2\" not in misc_T2) and (prononciation1 != \"_\" and prononciation2 != \"_\" and prononciation1 != \"FUSED\" and prononciation2 != \"FUSED\" and prononciation1 and prononciation2 and pos_T1 != \"PUNCT\" and pos_T2 != \"PUNCT\"):\n",
    "                    key = f\"{form_T1}-{form_T2}\"\n",
    "                    sub_key = f\"/{prononciation1}/-/{prononciation2}/\"\n",
    "                    if key not in occurences:\n",
    "                        occurences[key] = {sub_key: 1}\n",
    "                    else:\n",
    "                        if sub_key not in occurences[key]:\n",
    "                            occurences[key][sub_key] = 1\n",
    "                        else:\n",
    "                            occurences[key][sub_key] += 1\n",
    "\n",
    "            index += 1\n",
    "            \n",
    "    # print(occurences)\n",
    "    return occurences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_occ_homophone_bi(conllu_path:str):\n",
    "    \"\"\"\n",
    "    Extrait les occurrences d'une suite de 2 tokens homophones dans un corpus CoNLL-U.Regarde dans misc syl1.\n",
    "\n",
    "    Parameters:\n",
    "    conllu_path (str): le chemin du fichier CoNLL-U\n",
    "\n",
    "    Returns:\n",
    "    dict: un dictionnaire avec les occurrences des suites de 2 tokens homophones\n",
    "    \"\"\"\n",
    "    occurences = {}\n",
    "    # Convertir le fichier conllu en arbres de dépendances\n",
    "    trees = conllFile2trees(conllu_path)\n",
    "    for tree in trees:\n",
    "        # Convertir l'arbre en chaîne de caractères\n",
    "        tree_str = str(tree)\n",
    "\n",
    "        words = tree.words\n",
    "        index = 1\n",
    "\n",
    "        while index < len(words):\n",
    "            form_T1 = tree[index].get(\"t\", \"_\")\n",
    "            pos = tree[index].get(\"tag\", \"_\")\n",
    "            pos_T1 = pos\n",
    "            misc_T1 = tree[index].get(\"misc\", \"\")\n",
    "            misc_T1_dict = convert_misc_to_dict(misc_T1)\n",
    "            prononciation1_syl1 = misc_T1_dict.get(\"Syl1\", \"_\")\n",
    "            prononciation1_syl2 = misc_T1_dict.get(\"Syl2\", \"_\")\n",
    "            prononciation = f\"{prononciation1_syl1}{prononciation1_syl2}\"\n",
    "\n",
    "\n",
    "            idx = index + 1\n",
    "\n",
    "            if idx < len(words):\n",
    "                form_T2 = tree[idx].get(\"t\", \"_\")\n",
    "                pos_T2 = tree[idx].get(\"tag\", \"_\")\n",
    "                misc_T2 = tree[idx].get(\"misc\", \"\")\n",
    "                misc_T2_dict = convert_misc_to_dict(misc_T2)\n",
    "                prononciation2_syl1 = misc_T2_dict.get(\"Syl1\", \"_\")\n",
    "                prononciation2_syl2 = misc_T2_dict.get(\"Syl2\", \"_\")\n",
    "                prononciation2 = f\"{prononciation2_syl1}{prononciation2_syl2}\"\n",
    "\n",
    "                if (prononciation == prononciation2 and pos_T1 != pos_T2) and (\"Syl2\" in misc_T1 and \"Syl2\" in misc_T2 and \"Syl3\" not in misc_T1 and \"Syl3\" not in misc_T2) and (\"_\" not in prononciation and \"_\" not in prononciation2 and \"FUSED\" not in prononciation and \"FUSED\" not in prononciation2 and pos_T1 != \"PUNCT\" and pos_T2 != \"PUNCT\"):\n",
    "                    key = f\"{form_T1}-{form_T2}\"\n",
    "                    sub_key = f\"/{prononciation}/-/{prononciation2}/\"\n",
    "                    sub_sub_key_slope = f\"{prononciation1_syl1}-{prononciation2_syl1}\"\n",
    "                    if key not in occurences:\n",
    "                        occurences[key] = {sub_key: 1}\n",
    "                    else:\n",
    "                        if sub_key not in occurences[key]:\n",
    "                            occurences[key][sub_key] = 1\n",
    "                        else:\n",
    "                            occurences[key][sub_key] += 1\n",
    "\n",
    "            index += 1\n",
    "            \n",
    "    # print(occurences)\n",
    "    return occurences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_occurrences_obj(directory_path):\n",
    "    # Dictionnaire pour stocker toutes les occurrences d'objets\n",
    "    occurrences = {}\n",
    "    # Parcourir tous les fichiers du répertoire\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        if \"non_gold\" in dirs:\n",
    "            dirs.remove(\"non_gold\")\n",
    "        for file in files:\n",
    "            # Vérifier si le fichier est au format conllu et contient \"MG\" dans son nom\n",
    "            if file.endswith(\".conllu\") and \"MG\" in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Extraire les occurrences d'objets du fichier et les ajouter au dictionnaire des occurrences\n",
    "                file_occurrences_mono = extract_occ_homophone_mono(file_path)\n",
    "                for key, sub_dict in file_occurrences_mono.items():\n",
    "                    if key not in occurrences:\n",
    "                        occurrences[key] = sub_dict\n",
    "                    else:\n",
    "                        for sub_key, count in sub_dict.items():\n",
    "                            if sub_key in occurrences[key]:\n",
    "                                occurrences[key][sub_key] += count\n",
    "                            else:\n",
    "                                occurrences[key][sub_key] = count\n",
    "                                \n",
    "                \n",
    "                file_occurrences_bi = extract_occ_homophone_bi(file_path)\n",
    "                for key, sub_dict in file_occurrences_bi.items():\n",
    "                    if key not in occurrences:\n",
    "                        occurrences[key] = sub_dict\n",
    "                    else:\n",
    "                        for sub_key, count in sub_dict.items():\n",
    "                            if sub_key in occurrences[key]:\n",
    "                                occurrences[key][sub_key] += count\n",
    "                            else:\n",
    "                                occurrences[key][sub_key] = count\n",
    "\n",
    "    filtered_sorted_occurrences = {}\n",
    "    for key, sub_dict in occurrences.items():\n",
    "        # Filtrer les sous-dictionnaires pour garder les valeurs > 1\n",
    "        filtered_sub_dict = {sub_key: count for sub_key, count in sub_dict.items() if count > 1}\n",
    "        if filtered_sub_dict:  # Ajouter seulement si le sous-dictionnaire n'est pas vide\n",
    "            sorted_sub_dict = dict(sorted(filtered_sub_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "            filtered_sorted_occurrences[key] = sorted_sub_dict\n",
    "    return filtered_sorted_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de-dey': {'/de/-/de/': 67, '/dE/-/dE/': 3},\n",
      " 'no-know': {'/no/-/no/': 65},\n",
      " 'for-four': {'/fO/-/fO/': 2},\n",
      " 'go-go': {'/go/-/go/': 65},\n",
      " 'dey-dere': {'/de/-/de/': 2},\n",
      " 'dere-dey': {'/de/-/de/': 2},\n",
      " 'way-wey': {'/we/-/we/': 13},\n",
      " 'dey-dey': {'/de/-/de/': 12},\n",
      " 'con-come': {'/kO~/-/kO~/': 6},\n",
      " 'ah-I': {'/a/-/a/': 3},\n",
      " 'fall-for': {'/fO/-/fO/': 7},\n",
      " 'dem-dey': {'/de/-/de/': 5},\n",
      " 'now-na': {'/na/-/na/': 2},\n",
      " 'come-con': {'/kO~/-/kO~/': 2},\n",
      " 'none-of': {'/nO/-/nO/': 2},\n",
      " 'we-will': {'/wi/-/wi/': 2}}\n",
      "\n",
      "homophones extraits !\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"/Users/perrine/Desktop/Stage_2023-2024/SUD_Naija-NSC-master/\"\n",
    "\n",
    "# Extraire les occurrences d'objets de tous les fichiers du répertoire\n",
    "homophones = extract_all_occurrences_obj(directory_path)\n",
    "pprint.pp(homophones)\n",
    "print(\"\\nhomophones extraits !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
